{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of data loading and model training with BERT vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_DATA_DIR = os.path.join(\"..\", \"handout\", \"data\")\n",
    "BERT_FEATURE_DIR = \"bert_output_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format training data\n",
    "\n",
    "`X` will be a matrix with `N` rows for the `N` texts in the training data, and `M` columns for the `M` features generated by BERT.\n",
    "\n",
    "`y` will be an array of `N` class labels for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(ORIGINAL_DATA_DIR, \"lang_id_train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(ORIGINAL_DATA_DIR, \"lang_id_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vectors = []\n",
    "with open(os.path.join(BERT_FEATURE_DIR, \"train.jsonlines\"), \"rt\") as infile:\n",
    "    for line in infile:\n",
    "        bert_data = json.loads(line)\n",
    "        for t in bert_data[\"features\"]:\n",
    "            # Only extract the [CLS] vector used for classification\n",
    "            if t[\"token\"] == \"[CLS]\":\n",
    "                # We only use the representation at the final layer of the network\n",
    "                bert_vectors.append(t[\"layers\"][0][\"values\"])\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "print(len(bert_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(bert_vectors)\n",
    "y = train_df[\"native_language\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegression(penalty=\"l2\", C=1.0)\n",
    "lr_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = []\n",
    "with open(os.path.join(BERT_FEATURE_DIR, \"test.jsonlines\"), \"rt\") as infile:\n",
    "    for line in infile:\n",
    "        bert_data = json.loads(line)\n",
    "        for t in bert_data[\"features\"]:\n",
    "            # Only extract the [CLS] vector used for classification\n",
    "            if t[\"token\"] == \"[CLS]\":\n",
    "                # We only use the representation at the final layer of the network\n",
    "                test_vectors.append(t[\"layers\"][0][\"values\"])\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(test_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in percentage: 46.6\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(test_vectors)\n",
    "test_labels = lr_model.predict(x_test)\n",
    "y_test = test_df[\"native_language\"].values\n",
    "accuracy = lr_model.score(x_test, y_test)\n",
    "print(\"Accuracy in percentage: \" + str(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predicted_language'] = test_labels\n",
    "test_df['result']=np.where(test_df['native_language'] == test_df['predicted_language'],'Yes','No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_df = test_df[test_df.native_language.isin(['Arabic'])]\n",
    "cantonese_df = test_df[test_df.native_language.isin(['Cantonese'])]\n",
    "japanese_df = test_df[test_df.native_language.isin(['Japanese'])]\n",
    "korean_df = test_df[test_df.native_language.isin(['Korean'])]\n",
    "mandarin_df = test_df[test_df.native_language.isin(['Mandarin'])]\n",
    "polish_df = test_df[test_df.native_language.isin(['Polish'])]\n",
    "russian_df = test_df[test_df.native_language.isin(['Russian'])]\n",
    "spanish_df = test_df[test_df.native_language.isin(['Spanish'])]\n",
    "thai_df = test_df[test_df.native_language.isin(['Thai'])]\n",
    "vietnamese_df = test_df[test_df.native_language.isin(['Vietnamese'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(arabic_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = sklearn.metrics.confusion_matrix(test_df['native_language'], test_df['predicted_language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 99  11   9   7  12  14  10  16   9  13]\n",
      " [ 11  68  14  12  46  12  10   4   9  14]\n",
      " [  8  13  99  23  11  17  10   5   5   9]\n",
      " [  7  17  23  91  13   8  12   9  12   8]\n",
      " [ 12  36  19  14  63   9  10  14   6  17]\n",
      " [ 11  14   8   3   5 102  29  11   8   9]\n",
      " [ 10   8  14   5   6  23 114  14   0   6]\n",
      " [ 17   2  11   5  14  17  14 104   5  11]\n",
      " [ 12  10   7  15   9   2   1  13 120  11]\n",
      " [ 12  29  11  13  19  13  12  11   8  72]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies of misclassifications between each pair of classes: \n",
      " [[0.495 0.055 0.045 0.035 0.06  0.07  0.05  0.08  0.045 0.065]\n",
      " [0.055 0.34  0.07  0.06  0.23  0.06  0.05  0.02  0.045 0.07 ]\n",
      " [0.04  0.065 0.495 0.115 0.055 0.085 0.05  0.025 0.025 0.045]\n",
      " [0.035 0.085 0.115 0.455 0.065 0.04  0.06  0.045 0.06  0.04 ]\n",
      " [0.06  0.18  0.095 0.07  0.315 0.045 0.05  0.07  0.03  0.085]\n",
      " [0.055 0.07  0.04  0.015 0.025 0.51  0.145 0.055 0.04  0.045]\n",
      " [0.05  0.04  0.07  0.025 0.03  0.115 0.57  0.07  0.    0.03 ]\n",
      " [0.085 0.01  0.055 0.025 0.07  0.085 0.07  0.52  0.025 0.055]\n",
      " [0.06  0.05  0.035 0.075 0.045 0.01  0.005 0.065 0.6   0.055]\n",
      " [0.06  0.145 0.055 0.065 0.095 0.065 0.06  0.055 0.04  0.36 ]]\n"
     ]
    }
   ],
   "source": [
    "misclassification_rate = confusion_matrix/200\n",
    "print(\"Frequencies of misclassifications between each pair of classes: \\n\", misclassification_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision,recall,fscore,support = sklearn.metrics.precision_recall_fscore_support(test_df['native_language'], test_df['predicted_language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Arabic\" Class Metrics:\n",
      "\tMissClassification Rate: 0.505\n",
      "\tPrecision: 0.49748743718592964\n",
      "\tRecall: 0.495\n",
      "\tFscore: 0.4962406015037594\n",
      "\n",
      "\"Cantonese\" Class Metrics:\n",
      "\tMissClassification Rate: 0.6599999999999999\n",
      "\tPrecision: 0.3269230769230769\n",
      "\tRecall: 0.34\n",
      "\tFscore: 0.3333333333333333\n",
      "\n",
      "\"Japanese\" Class Metrics:\n",
      "\tMissClassification Rate: 0.505\n",
      "\tPrecision: 0.4604651162790698\n",
      "\tRecall: 0.495\n",
      "\tFscore: 0.47710843373493983\n",
      "\n",
      "\"Korean\" Class Metrics:\n",
      "\tMissClassification Rate: 0.5449999999999999\n",
      "\tPrecision: 0.48404255319148937\n",
      "\tRecall: 0.455\n",
      "\tFscore: 0.46907216494845355\n",
      "\n",
      "\"Mandarin\" Class Metrics:\n",
      "\tMissClassification Rate: 0.685\n",
      "\tPrecision: 0.3181818181818182\n",
      "\tRecall: 0.315\n",
      "\tFscore: 0.3165829145728643\n",
      "\n",
      "\"Polish\" Class Metrics:\n",
      "\tMissClassification Rate: 0.49\n",
      "\tPrecision: 0.4700460829493088\n",
      "\tRecall: 0.51\n",
      "\tFscore: 0.48920863309352525\n",
      "\n",
      "\"Russian\" Class Metrics:\n",
      "\tMissClassification Rate: 0.43000000000000005\n",
      "\tPrecision: 0.5135135135135135\n",
      "\tRecall: 0.57\n",
      "\tFscore: 0.5402843601895734\n",
      "\n",
      "\"Spanish\" Class Metrics:\n",
      "\tMissClassification Rate: 0.48\n",
      "\tPrecision: 0.5174129353233831\n",
      "\tRecall: 0.52\n",
      "\tFscore: 0.5187032418952618\n",
      "\n",
      "\"Thai\" Class Metrics:\n",
      "\tMissClassification Rate: 0.4\n",
      "\tPrecision: 0.6593406593406593\n",
      "\tRecall: 0.6\n",
      "\tFscore: 0.6282722513089005\n",
      "\n",
      "\"Vietnamese\" Class Metrics:\n",
      "\tMissClassification Rate: 0.64\n",
      "\tPrecision: 0.4235294117647059\n",
      "\tRecall: 0.36\n",
      "\tFscore: 0.3891891891891892\n"
     ]
    }
   ],
   "source": [
    "print(\"\\\"Arabic\\\" Class Metrics:\")\n",
    "print(\"\\tMissClassification Rate:\", 1-sklearn.metrics.accuracy_score(arabic_df['native_language'], arabic_df['predicted_language']))\n",
    "print(\"\\tPrecision:\", precision[0])\n",
    "print(\"\\tRecall:\", recall[0])\n",
    "print(\"\\tFscore:\", fscore[0])\n",
    "\n",
    "print(\"\\n\\\"Cantonese\\\" Class Metrics:\")\n",
    "print(\"\\tMissClassification Rate:\", 1-sklearn.metrics.accuracy_score(cantonese_df['native_language'], cantonese_df['predicted_language']))\n",
    "print(\"\\tPrecision:\", precision[1])\n",
    "print(\"\\tRecall:\", recall[1])\n",
    "print(\"\\tFscore:\", fscore[1])\n",
    "\n",
    "print(\"\\n\\\"Japanese\\\" Class Metrics:\")\n",
    "print(\"\\tMissClassification Rate:\", 1-sklearn.metrics.accuracy_score(japanese_df['native_language'], japanese_df['predicted_language']))\n",
    "print(\"\\tPrecision:\", precision[2])\n",
    "print(\"\\tRecall:\", recall[2])\n",
    "print(\"\\tFscore:\", fscore[2])\n",
    "\n",
    "print(\"\\n\\\"Korean\\\" Class Metrics:\")\n",
    "print(\"\\tMissClassification Rate:\", 1-sklearn.metrics.accuracy_score(korean_df['native_language'], korean_df['predicted_language']))\n",
    "print(\"\\tPrecision:\", precision[3])\n",
    "print(\"\\tRecall:\", recall[3])\n",
    "print(\"\\tFscore:\", fscore[3])\n",
    "\n",
    "\n",
    "print(\"\\n\\\"Mandarin\\\" Class Metrics:\")\n",
    "print(\"\\tMissClassification Rate:\", 1-sklearn.metrics.accuracy_score(mandarin_df['native_language'], mandarin_df['predicted_language']))\n",
    "print(\"\\tPrecision:\", precision[4])\n",
    "print(\"\\tRecall:\", recall[4])\n",
    "print(\"\\tFscore:\", fscore[4])\n",
    "\n",
    "print(\"\\n\\\"Polish\\\" Class Metrics:\")\n",
    "print(\"\\tMissClassification Rate:\", 1-sklearn.metrics.accuracy_score(polish_df['native_language'], polish_df['predicted_language']))\n",
    "print(\"\\tPrecision:\", precision[5])\n",
    "print(\"\\tRecall:\", recall[5])\n",
    "print(\"\\tFscore:\", fscore[5])\n",
    "\n",
    "print(\"\\n\\\"Russian\\\" Class Metrics:\")\n",
    "print(\"\\tMissClassification Rate:\", 1-sklearn.metrics.accuracy_score(russian_df['native_language'], russian_df['predicted_language']))\n",
    "print(\"\\tPrecision:\", precision[6])\n",
    "print(\"\\tRecall:\", recall[6])\n",
    "print(\"\\tFscore:\", fscore[6])\n",
    "\n",
    "print(\"\\n\\\"Spanish\\\" Class Metrics:\")\n",
    "print(\"\\tMissClassification Rate:\", 1-sklearn.metrics.accuracy_score(spanish_df['native_language'], spanish_df['predicted_language']))\n",
    "print(\"\\tPrecision:\", precision[7])\n",
    "print(\"\\tRecall:\", recall[7])\n",
    "print(\"\\tFscore:\", fscore[7])\n",
    "\n",
    "print(\"\\n\\\"Thai\\\" Class Metrics:\")\n",
    "print(\"\\tMissClassification Rate:\", 1-sklearn.metrics.accuracy_score(thai_df['native_language'], thai_df['predicted_language']))\n",
    "print(\"\\tPrecision:\", precision[8])\n",
    "print(\"\\tRecall:\", recall[8])\n",
    "print(\"\\tFscore:\", fscore[8])\n",
    "\n",
    "print(\"\\n\\\"Vietnamese\\\" Class Metrics:\")\n",
    "print(\"\\tMissClassification Rate:\", 1-sklearn.metrics.accuracy_score(vietnamese_df['native_language'], vietnamese_df['predicted_language']))\n",
    "print(\"\\tPrecision:\", precision[9])\n",
    "print(\"\\tRecall:\", recall[9])\n",
    "print(\"\\tFscore:\", fscore[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
